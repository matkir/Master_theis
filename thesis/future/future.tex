The task of making general models to cover a broad aspect of medical images is still a widely researched area today, and most likely, it will continue to be so in the future. There are a  plethora of different ways to build models for the medical domain, and in most of them, there is room for improvement.

\section{Conclusion}
We have seen the power of inpainting when it comes to datasets previously unseen during training. Both shown in our publications and the thesis, we have an increase in classification score on multiple types of inpainting.
Unfortunately, we often get inconsistent results during testing, which means that we cannot recommend any method over another, as both the testing and training dataset influences the results.
In general, we saw an improvement when it came to inpainting, but the improvement differed between the two datasets. 

For the CVC 356 dataset removing artefacts within the image gave the best result for both models. When inpainting areas within the image the GAN won five out of six times, making it the best model for inpainting  areas with great detail. The good results lie also in the network used. The Densenet model worked excellent for the classification of this dataset.


For the CVC 12k dataset, we saw lower scores in general, confirming that this dataset is notoriously harder to classify. We did get the only improvement using inpainting of the borders around the Kvasir dataset during training, giving us believe that the network gained accuracy from the ´´distilled'' data provided when the borders were removed. 

The Kvasir dataset did not see anything else than a marginal improvement to an already high score. We will not draw any conclusions from the result, given the statistical uncertainties when the scores are so close to the baseline.


Finally, the act of inpainting both the corners and the green square gave us the highest score on the CVC 356 dataset, and a decent score for the CVC 12k dataset. The excellent scores give us some merit to believe that the two inpainting models can work together without interfering destructively with each other. 



\section{Future work}
The Work done in this thesis show that there might be improvements when classifying images with non-perfect information. There is still much work that can be done, both to improve inpainting and classification, and to better understand the ´´black box'' that is machine learning. 

\paragraph{Better performance GAN}
Since the start of this project, there have been published multiple new papers concerning making realistic GANs including \cite{DBLP:journals/corr/abs-1809-11096} \cite{DBLP:journals/corr/abs-1812-04948}. As this is still a relatively new research field, there are still many improvements that could be done to make the models better.
The best way to improve the GAN models is just to let them train longer. The latest model used to generate the inpainted dataset were running for approximately 40 hours, which is still away from reaching the best result. By using more time when training the models, we might achieve even better MCC when classifying the medical datasets.
Another way that might improve the GAN is better utilisation of the channel-wise fully-connected layer. In this thesis, this layer was a quintessential part of the result we got, and by tweaking the layers might give even better results.

\paragraph{Looking into using the generated images for classification}
The images generated by the GAN will most likely have features that are an essential part of the original image. If this is the same underlying features that are used in, for instance, DenseNet or Inceptionresnet we might not need to paste the inpainted area back into the original image.
Further research regarding the generator learning features from the different classes could show good results.
Another promising aspect of this is to let the discriminator guess the class in addition to real and fake images. If that is the case, the generator needs to learn features that define the different classes. We can see from images like Figure \ref{fig:p_GAN_BOTH2} that this, to a case, is already happening without making an auxiliary GAN.
In the end, the ability to compress the images with a GAN or AE might give us a new way to classify images.

\paragraph{Experiment with self attention}
We touched upon self attention in section \ref{cha:attention}. Though we did some experiments with self attention, more testing is required for a conclusion if its good or not in the context of this thesis. Future work should be to implement the attention layer into the GAN to see if the reconstructed areas can become better. 

5%\paragraph{Cropping of images}
%dsgfsgsgw

\paragraph{Make a generator for new data}
We have used the GAN and AE to exclusively inpaint images, but both models can, without any extensive modifications,  generate data from the same image domain from the original dataset, just like the original DCGAN ~\cite{DBLP:journals/corr/RadfordMC15} does.  
By using the dataset to generate new previously unseen data, we might help classification not to overfit.

\paragraph{Improving the program to work cross domain}
For future work, we would like to automate the process of inpainting by making the models look better, and give the user the option of choosing their areas to inpaint. The model presented can be used at any dataset, but the user has to edit the masks manually. 

\paragraph{Using OCR to remove text}
We tested the option to remove text using an Optical Character Recognition (OCR) during this thesis, but the time used by OCR algorithms are too slow to work in real-time. Combining the system presented in this thesis with a system like Rosetta~\cite{borisyuk2018rosetta} or EAST~\cite{DBLP:journals/corr/ZhouYWWZHL17} might give a speedup, but at the conclusion of this thesis, we are not able to run OCR and classification without a multi-GPU setup.


\paragraph{NASNetLarge}
When we chose our general model for classification back in August 2018, we used InceptionResNetV2 as our model. Since then F. Chollet has added NASNetLarge~\cite{DBLP:journals/corr/ZophVSL17} to the list of transfer learning models. NASNetLarge has a higher accuracy on the imagenet model and should possibly be the standard model for the classification.


