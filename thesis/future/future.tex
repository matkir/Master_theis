The task of making general models to cover a vide aspect of medical images is still a widely researched area today, and most likely, it will continue to be so in the near future. There are a  plethora of different ways to build models for the medical domain, and in most of them, there is room for improvement.
When looking at the results from the experiments, we can see \todo{more}

\section{Discussion of the results}
We have seen the power of inpainting when it comes to datasets previously unseen during training.
More
\section{Future work}

\paragraph{Better performance GAN}
Since the start of this project, there have been published multiple new papers concerning making realistic GANs \cite{DBLP:journals/corr/abs-1809-11096} \cite{DBLP:journals/corr/abs-1812-04948}. As this is still a relatively new research field, there are still many improvements that could be done to make the models better.
The best way to improve the gan models is just to let them train longer. The latest model used to generate the inpainted dataset were running for approximately 40 hours, which is still a long way from reaching the best result. By using more time when training the models, we might achieve even better MCC when classifying the medical datasets.
Another way that might improve the GAN is better utilisation of the channel-wise fully-conneted layer. In this thesis, this layer was a quintessential part of the result we got, and by tweaking the layers might give even better results.


\paragraph{Looking into using the generated images for classification}
The images generated by the GAN will most likely have features that are defined by the class it originates from. If this is the same underlying features that are used in, for instance, DenseNet or Inceptionresnet we might not need to past the inpainted area back into the original image.
Further research regarding the generator learning features from the different classes could show good results.

\paragraph{Make a generator for new data}
We have used the GAN and autoencoder to exclusively inpaint images, but both models can generate data from the same image domain from the original dataset.
By using the dataset to generate new previously unseen data, we might help classification not to overfit.



\paragraph{Improving the program to work cross domain}
For future work, we would like to automate the process of inpainting by making the models look better, and give the user the option of choosing their areas to inpaint. The model presented can be used at any dataset, but the user has to edit the masks manually. 

\paragraph{Using OCR to remove text}
The option to remove text using an Optical Character Recognition (OCR) has the foundation it needs, but the time used by OCR algorithms are to slow to work in real-time. 
Combining this system with a system like \todo{OCRMODELS} might give a speedup, but at this point requires a multi-GPU setup to work.

Another possible future branch is to look at entirely generated medical images as training data of a classifier. 


\paragraph{AUX GAN}
\ref{fig:p_GAN_BOTH2} shows that we might need class info to train the images.