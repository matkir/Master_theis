The task of making general models to cover a vide aspect of medical images is still a widely researched area today, and most likely, it will continue. There are a  plethora of different ways to build models for the medical domain, and, in most of them,  there is room for improvement.

For future work, we would like to automate the process of inpainting by making the models look better, and give the user the option of choosing their areas to inpaint. The model presented can be used at any dataset, but the user has to edit the masks manually. 
The option to remove text using an Optical Character Recognition (OCR) has the foundation it needs, but the time used by OCR algorithms are to slow to work in real-time. 
Combining this system with a system like \todo{OCRMODELS} might give a speedup, but at this point requires a multi-GPU setup to work.

Another possible future branch is to look at entirely generated medical images as training data of a classifier. 